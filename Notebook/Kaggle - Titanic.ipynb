{"nbformat": 4, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "version": "3.4.3", "nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat_minor": 0, "cells": [{"source": "#Titanic - Kaggle Training", "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": "import numpy as np\nimport pandas as pd\nimport csv as csv\nimport sys\n#set PYTHONPATH\nsys.path.append('C:/Users/User/Desktop/datasciences_tools/')\n\nimport os\nfrom time import time\nimport operator\n\nfrom Tools.tools import *\n\nfrom sklearn.tree import *\nfrom sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\nfrom sklearn import linear_model as lm\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC, LinearSVC\nimport sklearn.svm as svm\nfrom sklearn.preprocessing import *\nfrom sklearn.grid_search import GridSearchCV, RandomizedSearchCV    \n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n%qtconsole", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 1}, {"outputs": [{"metadata": {}, "data": {"text/plain": "1"}, "execution_count": 2, "output_type": "execute_result"}], "source": "# Multiprocessing\nos.system('taskset -p 0xffffffff %d' % os.getpid())", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 2}, {"source": "##Preprocessing", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"text": "C:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\nC:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n", "output_type": "stream", "name": "stderr"}], "source": "train = pd.read_csv(\"M:/datasciences/Projets/Kaggle/Titanic/train.csv\")\ntest = pd.read_csv(\"M:/datasciences/Projets/Kaggle/Titanic/test.csv\")\n#train = pd.read_csv(\"C:/Users/User/Desktop/datasciences_tools/data/train.csv\")\n#test = pd.read_csv(\"C:/Users/User/Desktop/datasciences_tools/data/test.csv\")\n\n## NA imputation\nfeature_columns_to_use = ['Pclass', 'Sex', 'Age', 'Fare', 'Parch', 'Embarked', 'SibSp']\nbig_X = train[feature_columns_to_use].append(test[feature_columns_to_use])\nbig_X_imputed = DataFrameImputer().fit_transform(big_X)\n\n# Let's rebuild train & test datasets with imputed values\ntrain_X = big_X_imputed[:train.shape[0]]\ntest_X = big_X_imputed[train.shape[0]:]\n\n# Male = 1 / Female = 0  using map function\ntrain_X['Gender'] = train_X['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\ntest_X['Gender'] = test_X['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\ntrain_X = train_X.drop(['Sex'], axis=1)\ntest_X = test_X.drop(['Sex'], axis=1)\n\n## Dummies\n##Embarked split\ntrain_X = feature_to_dummy(train_X, 'Embarked')\ntest_X = feature_to_dummy(test_X, 'Embarked')\n\n#Pclass\ntrain_X = feature_to_dummy(train_X, 'Pclass')\ntest_X = feature_to_dummy(test_X, 'Pclass')\n\ntrain_Y = train['Survived']\n\n## Categorical variable => Ordinal encoding\n# TODO : check here http://fr.slideshare.net/DataRobot/gradient-boosted-regression-trees-in-scikitlearn?next_slideshow=1", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 4}, {"source": "##Data-visualisation\nTODO", "metadata": {}, "cell_type": "markdown"}, {"source": "## Features selection", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"metadata": {}, "data": {"text/plain": "array([[ 1.,  0.,  1.],\n       [ 0.,  1.,  0.],\n       [ 0.,  0.,  1.],\n       ..., \n       [ 0.,  0.,  1.],\n       [ 1.,  1.,  0.],\n       [ 1.,  0.,  1.]])"}, "execution_count": 5, "output_type": "execute_result"}], "source": "#with linear SVC **Gridsearched**\nlin_svc = LinearSVC(C=100)\nlin_svc.fit_transform(train_X, train_Y)\n\n#with rf **Gridsearched**\nrf = RandomForestClassifier(n_estimators=100, max_features=1, criterion='entropy') \nrf.fit_transform(train_X, train_Y)\n\n#with logitCV **NOT DONE YET!**\nlogitcv = lm.LogisticRegressionCV()\nlogitcv.fit_transform(train_X, train_Y)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 5}, {"source": "##Models", "metadata": {}, "cell_type": "markdown"}, {"source": "###Random Forests", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"metadata": {}, "data": {"text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0xbc26940>"}, "execution_count": 75, "output_type": "execute_result"}, {"metadata": {}, "data": {"text/plain": "<matplotlib.figure.Figure at 0xbc296d8>", "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAFDCAYAAAAu6SV7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n"}, "output_type": "display_data"}], "source": "model_rf = RandomForestClassifier(n_estimators = 10,\n                                  max_depth = None,\n                                  bootstrap = True,\n                                  criterion = \"entropy\")\n\n#features importance\nimp_list = list(zip(train_X.columns, np.transpose(forest.feature_importances_)))\nimp_list.sort(key=operator.itemgetter(1), reverse=True)\nimp_rf = pd.DataFrame(imp_list, columns=['features', 'imp'])\nimp_rf.plot(kind='bar', x='features')", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 75}, {"source": "Let's keep the 3 first features.\n####The next line can be change if we decide to keep more variable :", "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": "train_X_imp = rf.fit_transform(train_X, train_Y)", "metadata": {"trusted": false, "collapsed": true}, "cell_type": "code", "execution_count": 76}, {"outputs": [], "source": "#combining the feature with pipeline.FeatureUnion => use it in the grid\ncombined_features = FeatureUnion([(\"rf_select\", rf), (\"rf_est\", model_rf)])\n# Use combined features to transform dataset: \nX_features = combined_features.fit(train_X, train_Y).transform(train_X)\n#TODO : modifier la FeatureUnion qui ne sert \u00e0 rien ici.\n", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": null}, {"source": "###SVC", "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": "##SVC-lin\nmodel_svc = svm.SVC(kernel='linear')\nres_svc = model_svc.fit(train_X, train_Y) ", "metadata": {"trusted": false, "collapsed": true}, "cell_type": "code", "execution_count": 53}, {"source": "###Logistic", "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": "## Logistic\nmodel_logit = lm.LogisticRegression()\nres_logit = model_logit.fit(train_X, train_Y)\n#coef\npd.DataFrame(list(zip(train_X.columns, np.transpose(res_logit.coef_))))", "metadata": {"trusted": false, "collapsed": true}, "cell_type": "code", "execution_count": null}, {"source": "##Find the best parameters (Gridsearch)", "metadata": {}, "cell_type": "markdown"}, {"source": "###Grid - parameters", "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": "param_grid_rf = {\"n_estimators\" : [10, 20, 30, 50, 100, 110, 150, 180, 190],\n              \"max_depth\": [3, None],\n              \"max_features\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n              \"min_samples_split\": [1, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n              \nparam_grid_svc = [\n  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n ]\n\nparam_grid_GBR = {\n              'learning_rate': [0.1, 0.05, 0.02, 0.01],\n              'max_depth': [4, 6],\n              'min_samples_leaf': [3, 5, 9, 17, 100],\n              'max_features': [1.0, 0.3, 0.1], #percentage\n              }\n\nparam_grid_ada = {\n            'n_estimators': [15, 20, 25, 30, 35, 40, 45, 100],\n            'learning_rate': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n            'random_state' : [10,20,30,40,50,70,80,90]\n            }\n\nparam_ExtraTrees = {\n            'n_estimators': [100,200,300,400,500,600,700,1000],\n            'max_depth': [1, 2, 5, 7, 10],\n            'min_samples_leaf': [1, 2 , 5, 7, 10],\n            'min_samples_split': [1, 2 , 5, 7, 10]\n            }\n\nparam_grid_logit = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n                   'random_state' : [10,20,30,40,50,70,80,90]\n                   }\n\n    ", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 39}, {"source": "### Hyperparametrisation (gridsearch)", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"text": "GridSearchCV took 285.91 seconds for 6480 candidate parameter settings.\nModel with rank: 1\nMean validation score: 0.840 (std: 0.028)\nParameters: {'max_features': 0.6, 'min_samples_split': 3, 'criterion': 'entropy', 'n_estimators': 110, 'max_depth': None, 'bootstrap': True, 'min_samples_leaf': 3}\n\nModel with rank: 2\nMean validation score: 0.837 (std: 0.020)\nParameters: {'max_features': 0.5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'n_estimators': 50, 'max_depth': None, 'bootstrap': True, 'min_samples_split': 10}\n\nModel with rank: 3\nMean validation score: 0.837 (std: 0.023)\nParameters: {'max_features': 0.8, 'min_samples_split': 1, 'criterion': 'entropy', 'n_estimators': 180, 'max_depth': None, 'bootstrap': True, 'min_samples_leaf': 3}\n\n", "output_type": "stream", "name": "stdout"}], "source": "model_rf = RandomForestClassifier()\ngrid_search = GridSearchCV(model_rf, param_grid=param_grid_rf, n_jobs=12)\nstart = time()\ngrid_search.fit(train_X, train_Y)\n\nprint(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n      % (time() - start, len(grid_search.grid_scores_)))\nreport_grid(grid_search.grid_scores_)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 16}, {"outputs": [{"text": "GridSearchCV took 270.82 seconds for 12 candidate parameter settings.\nModel with rank: 1\nMean validation score: 0.789 (std: 0.020)\nParameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n\nModel with rank: 2\nMean validation score: 0.788 (std: 0.010)\nParameters: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n\nModel with rank: 3\nMean validation score: 0.787 (std: 0.011)\nParameters: {'C': 1, 'kernel': 'linear'}\n\n", "output_type": "stream", "name": "stdout"}], "source": "grid_search = GridSearchCV(model_svc, param_grid=param_grid_svc, n_jobs=12)\nstart = time()\ngrid_search.fit(train_X, train_Y)\n\nprint(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n      % (time() - start, len(grid_search.grid_scores_)))\nreport_grid(grid_search.grid_scores_)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 80}, {"source": "This is how you tune GradientBoostingClassifier :\n\n1. Set n_estimators very high (eg 3000)\n2. grid search learning_rate, max_depth, min_sample_leaf & max_features", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"text": "It took 112.37442779541016 seconds\nModel with rank: 1\nMean validation score: 0.826 (std: 0.016)\nParameters: {'max_features': 0.3, 'min_samples_leaf': 100, 'learning_rate': 0.05, 'max_depth': 4}\n\nModel with rank: 2\nMean validation score: 0.824 (std: 0.019)\nParameters: {'max_features': 0.3, 'min_samples_leaf': 100, 'learning_rate': 0.1, 'max_depth': 6}\n\nModel with rank: 3\nMean validation score: 0.824 (std: 0.030)\nParameters: {'max_features': 0.1, 'min_samples_leaf': 3, 'learning_rate': 0.01, 'max_depth': 4}\n\n", "output_type": "stream", "name": "stdout"}], "source": "GBR = GradientBoostingClassifier(n_estimators=3000)\nstart_time = time()\ngrid_search = GridSearchCV(GBR, param_grid_GBR, n_jobs=12).fit(train_X, train_Y)\nend_time = time()\nprint('It took {} seconds'.format(end_time - start_time))\nreport_grid(grid_search.grid_scores_)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 7}, {"source": "Now that we have the best hyperparameters settings :\n\n3. let's set n_estimators even higher (eg 9000)\n4. tune learning_rate as precisely as possible.", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"text": "It took 34.77398896217346 seconds\nModel with rank: 1\nMean validation score: 0.828 (std: 0.019)\nParameters: {'learning_rate': 0.021}\n\nModel with rank: 2\nMean validation score: 0.827 (std: 0.018)\nParameters: {'learning_rate': 0.019}\n\nModel with rank: 3\nMean validation score: 0.826 (std: 0.016)\nParameters: {'learning_rate': 0.014}\n\n", "output_type": "stream", "name": "stdout"}], "source": "GBR = GradientBoostingClassifier(n_estimators=9000, max_features=0.3, min_samples_leaf=100, max_depth=4)\nparam_GBR = { 'learning_rate': [0.01,0.012,0.013,0.014,0.015,0.016,0.017,0.18,0.019,0.02,0.021,0.025,0.026,0.027,0.028]}\nstart_time = time()\ngrid_search = GridSearchCV(GBR, param_GBR, n_jobs=12).fit(train_X, train_Y)\nend_time = time()\nprint('It took {} seconds'.format(end_time - start_time))\nreport_grid(grid_search.grid_scores_)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 14}, {"outputs": [{"text": "It took 1179.2584490776062 seconds\nModel with rank: 1\nMean validation score: 0.818 (std: 0.012)\nParameters: {'random_state': 70, 'n_estimators': 15, 'learning_rate': 0.3}\n\nModel with rank: 2\nMean validation score: 0.818 (std: 0.019)\nParameters: {'random_state': 90, 'n_estimators': 15, 'learning_rate': 0.3}\n\nModel with rank: 3\nMean validation score: 0.817 (std: 0.021)\nParameters: {'random_state': 10, 'n_estimators': 15, 'learning_rate': 0.3}\n\n", "output_type": "stream", "name": "stdout"}], "source": "best_rf = RandomForestClassifier(n_estimators = 110,\n                                  max_depth = None,\n                                  min_samples_leaf = 3,\n                                  max_features = 0.6,\n                                  min_samples_split = 10,\n                                  bootstrap = True,\n                                  criterion = \"entropy\")\n\nada_rf = AdaBoostClassifier(best_rf, n_estimators=4, random_state=93)\n\nstart_time = time()\ngrid_search = GridSearchCV(ada_rf, param_grid_ada, n_jobs=12).fit(train_X, train_Y)\nend_time = time()\nprint('It took {} seconds'.format(end_time - start_time))\nreport_grid(grid_search.grid_scores_)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 19}, {"outputs": [{"text": "It took 24.545403957366943 seconds\nModel with rank: 1\nMean validation score: 0.836 (std: 0.028)\nParameters: {'learning_rate': 0.027}\n\nModel with rank: 2\nMean validation score: 0.835 (std: 0.026)\nParameters: {'learning_rate': 0.026}\n\nModel with rank: 3\nMean validation score: 0.835 (std: 0.026)\nParameters: {'learning_rate': 0.028}\n\n", "output_type": "stream", "name": "stdout"}], "source": "param_ada = { 'learning_rate': [0.026,0.027,0.028, 0.029, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]}\nbest_rf = RandomForestClassifier(n_estimators = 110,\n                                  max_depth = None,\n                                  min_samples_leaf = 3,\n                                  max_features = 0.6,\n                                  min_samples_split = 10,\n                                  bootstrap = True,\n                                  criterion = \"entropy\")\n\nada_rf = AdaBoostClassifier(best_rf, n_estimators=15, random_state=70)\n\nstart_time = time()\ngrid_search = GridSearchCV(ada_rf, param_ada, n_jobs=12).fit(train_X, train_Y)\nend_time = time()\nprint('It took {} seconds'.format(end_time - start_time))\nreport_grid(grid_search.grid_scores_)\n", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 22}, {"outputs": [{"text": "It took 12.106693029403687 seconds\nModel with rank: 1\nMean validation score: 0.792 (std: 0.008)\nParameters: {'C': 100, 'random_state': 10}\n\nModel with rank: 2\nMean validation score: 0.792 (std: 0.008)\nParameters: {'C': 100, 'random_state': 20}\n\nModel with rank: 3\nMean validation score: 0.792 (std: 0.008)\nParameters: {'C': 100, 'random_state': 30}\n\n", "output_type": "stream", "name": "stdout"}], "source": "model_logit = lm.LogisticRegression(penalty='l2')\nstart_time = time()\ngrid_search = GridSearchCV(model_logit, param_grid_logit, n_jobs=12).fit(train_X, train_Y)\nend_time = time()\nprint('It took {} seconds'.format(end_time - start_time))\nreport_grid(grid_search.grid_scores_)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 40}, {"outputs": [{"metadata": {}, "data": {"text/plain": "<bound method LogisticRegressionCV.score of LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n           multi_class='ovr', n_jobs=1, penalty='l2', refit=True,\n           scoring=None, solver='lbfgs', tol=0.0001, verbose=0)>"}, "execution_count": 43, "output_type": "execute_result"}], "source": "#TODO !\nmodel_logitCV = lm.LogisticRegressionCV()\nmodel_logitCV.score", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 43}, {"source": "##Best models", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"text": "It took 5.360306024551392 seconds\nModel with rank: 1\nMean validation score: 0.801 (std: 0.029)\nParameters: {'learning_rate': 0.5, 'n_estimators': 45}\n\nModel with rank: 2\nMean validation score: 0.801 (std: 0.034)\nParameters: {'learning_rate': 0.8, 'n_estimators': 45}\n\nModel with rank: 3\nMean validation score: 0.801 (std: 0.029)\nParameters: {'learning_rate': 0.8, 'n_estimators': 100}\n\n", "output_type": "stream", "name": "stdout"}], "source": "best_adaboost = AdaBoostClassifier(\n        n_estimators = 20,\n        learning_rate = 0.75,\n        base_estimator = ExtraTreesClassifier(\n            n_estimators = 400,\n            max_features = 30,\n            max_depth = 12,\n            min_samples_leaf = 100,\n            min_samples_split = 100,\n            verbose = 1,\n            n_jobs = -1))\nPipe = Pipeline([('ada', adaboost), ('extra', extratree)])\n\nadaboost = AdaBoostClassifier()\nstart_time = time()\ngrid_search = GridSearchCV(adaboost, param_grid_ada, n_jobs=12).fit(train_X, train_Y)\nend_time = time()\nprint('It took {} seconds'.format(end_time - start_time))\nreport_grid(grid_search.grid_scores_)", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 47}, {"outputs": [], "source": "GBR = GradientBoostingClassifier(n_estimators=9000, max_features=0.3, min_samples_leaf=100, max_depth=4)\n\nbest_GBR = GradientBoostingClassifier(min_samples_leaf = 100,\n                                  learning_rate = 0.021,\n                                  max_depth = 4,\n                                  max_features = 0.3,\n                                  n_estimators = 9000)\n\nmodel_gbr = best_GBR.fit(train_X, train_Y)\noutput = model_gbr.predict(test_X).astype(int)\n\nbest_rf = RandomForestClassifier(n_estimators = 110,\n                                  max_depth = None,\n                                  min_samples_leaf = 3,\n                                  max_features = 0.6,\n                                  min_samples_split = 10,\n                                  bootstrap = True,\n                                  criterion = \"entropy\")\nmodel_rf = best_rf.fit(train_X, train_Y)\noutput = model_rf.predict(test_X).astype(int)\n\nada_rf = AdaBoostClassifier(best_rf, n_estimators=15, random_state=70, learning_rate=0.027)\nmodel_ada_rf = ada_rf.fit(train_X, train_Y)\noutput = model_ada_rf.predict(test_X).astype(int)\n\n\nbest_svc = svm.SVC(kernel = 'rbf',\n                  C = 100,\n                  gamma = 0.001)\nmodel_rf = best_svc.fit(train_X, train_Y)\n\nbest_adaboost = AdaBoostClassifier(\n        n_estimators = 20,\n        learning_rate = 0.75,\n        base_estimator = ExtraTreesClassifier(\n            n_estimators = 400,\n            max_features = 30,\n            max_depth = 12,\n            min_samples_leaf = 100,\n            min_samples_split = 100,\n            verbose = 1,\n            n_jobs = -1))\n\n\n", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 32}, {"source": "## Output", "metadata": {}, "cell_type": "markdown"}, {"outputs": [{"text": "Done.\n", "output_type": "stream", "name": "stdout"}], "source": "ids = test['PassengerId'].values\n\npredictions_file = open('M:/datasciences/Projets/Kaggle/Titanic/gbr_grid.csv', 'w', newline='')\nopen_file_object = csv.writer(predictions_file)\nopen_file_object.writerow([\"PassengerId\",\"Survived\"])\nopen_file_object.writerows(zip(ids, output))\npredictions_file.close()\nprint('Done.')", "metadata": {"trusted": false, "collapsed": false}, "cell_type": "code", "execution_count": 34}, {"outputs": [], "source": "", "metadata": {"trusted": false, "collapsed": true}, "cell_type": "code", "execution_count": null}]}